{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9882144a-bdce-432e-8d17-2462390515d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The objective of this notebook is to process bureau.csv and bureau_balance.csv to make Level 2 aggegrated deliquency features. \n",
    "The final goal is to have a single row features against each SK_ID_CURR which could be later joined with the application_train.csv so as to form final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ecc7236-94b6-47d6-bfbe-1d0f76e1c539",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "1. Importing libraries"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import when, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "641c5ddf-c5be-4e0f-b0d2-195440bae686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ignore SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15ad830a-c2ee-41a2-8331-c0259b438f18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from default.bureau limit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7edc63b-d672-41f4-9b0e-723a5d72863a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from default.bureau_balance limit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c256646-b293-43ee-861c-70520d495047",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "2. Basic Information on the data sets"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select count(distinct sk_id_curr) as customer_count, count(distinct SK_ID_BUREAU) as loan_count from default.bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1329e92-d4d1-4f52-bfa0-c17cc82fb452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select count(distinct SK_ID_BUREAU) as loan_count from default.bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c56d99b-391e-4b95-85ea-a87a3861d62b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "3. Initializing pyspark dataframes"
    }
   },
   "outputs": [],
   "source": [
    "bu_bal = spark.sql(\"select * from bureau_balance\")\n",
    "bu_main = spark.sql(\"select * from bureau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dbb83c9-72e1-42fc-add9-0e966acb9937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dropping duplicates from bu_bal\n",
    "bu_bal = bu_bal.dropDuplicates()\n",
    "bu_bal.createOrReplaceTempView(\"bu_bal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f368d2e6-cac2-4f57-81cc-b42388b281ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bu_bal.limit(2).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d82f2cf-c1eb-46f2-b9d0-1cf05fd44e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the mapping for STATUS replacement\n",
    "status_mapping = {\n",
    "    'C': 'C',\n",
    "    'X': 0,\n",
    "    '0': 0,\n",
    "    '1': 15,\n",
    "    '2': 45,\n",
    "    '3': 75,\n",
    "    '4': 105,\n",
    "    '5': 135\n",
    "}\n",
    "\n",
    "# Start with the original dataframe\n",
    "bu_bal = bu_bal.withColumn(\n",
    "    \"STATUS\",\n",
    "    when(col(\"STATUS\") == \"C\", \"C\")\n",
    "    .when(col(\"STATUS\") == \"X\", 0)\n",
    "    .when(col(\"STATUS\") == \"0\", 0)\n",
    "    .when(col(\"STATUS\") == \"1\", 15)\n",
    "    .when(col(\"STATUS\") == \"2\", 45)\n",
    "    .when(col(\"STATUS\") == \"3\", 75)\n",
    "    .when(col(\"STATUS\") == \"4\", 105)\n",
    "    .when(col(\"STATUS\") == \"5\", 135)\n",
    "    .otherwise(None)  # Set to None (null) for any value not in the mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "675e8dc0-5228-4687-af75-436e9675a8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Count occurrences of each unique value in the \"STATUS\" column\n",
    "status_counts = bu_bal.groupBy(\"STATUS\").count()\n",
    "\n",
    "# Display the result\n",
    "status_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b895d902-b739-404e-8b16-f19653d8f6da",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "4. flattening bu_bal and creating raw dpd variables"
    }
   },
   "outputs": [],
   "source": [
    "def create_raw_dpd_variables(df):\n",
    "\n",
    "    # Step 1: Filter rows where STATUS is not 'C' and add a dense rank for descending MONTHS_BALANCE within each SK_ID_BUREAU\n",
    "    window_spec = Window.partitionBy(\"SK_ID_BUREAU\").orderBy(F.desc(\"MONTHS_BALANCE\"))\n",
    "    df_filtered = (\n",
    "        df.filter(df['STATUS'] != 'C')\n",
    "          .withColumn(\"MOB\", F.dense_rank().over(window_spec))\n",
    "          .filter(F.col(\"MOB\") <= 36)\n",
    "    )\n",
    "\n",
    "    # Step 2: Pivot to have each SK_ID_BUREAU as a single row, with MOB values as columns\n",
    "    bu_bal_2 = df_filtered.groupBy(\"SK_ID_BUREAU\").pivot(\"MOB\", range(1, 37)).agg(F.first(\"STATUS\"))\n",
    "\n",
    "    # Step 3: Rename columns during the pivot to get dpd_1, dpd_2, ..., dpd_36\n",
    "    renamed_columns = [F.col(str(mob)).alias(f'dpd_{mob}') for mob in range(1, 37)]\n",
    "    bu_bal_2 = bu_bal_2.select(\"SK_ID_BUREAU\", *renamed_columns)\n",
    "\n",
    "    return bu_bal_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d91d8a1-182c-4ce3-b832-62f0d96fee89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bu_bal_flatten = create_raw_dpd_variables(bu_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8e1955-4540-4e0d-986b-8aaf45820921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bu_bal_flatten.display()\n",
    "bu_bal_flatten.createOrReplaceTempView(\"bu_bal_flatten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ffd2520-cdc7-47f2-8ff1-3bfbe8c3d711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select count(distinct SK_ID_BUREAU) as loan_cout from bu_bal_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b37f69a-9fef-422c-8bd3-9d416cfc1786",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "5. left join bureau main with flattened bureau balance tables"
    }
   },
   "outputs": [],
   "source": [
    "bu_main_with_raw_dpd = bu_main.join(bu_bal_flatten, on='SK_ID_BUREAU', how='left')\n",
    "bu_main_with_raw_dpd.createOrReplaceTempView('bu_main_with_raw_dpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566810c6-a51f-4640-93d6-55189d3960f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bu_main_with_raw_dpd limit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57846b2a-8a91-47c3-a56e-ab96c54f65fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select\n",
    "  count(distinct sk_id_curr) as user_count,\n",
    "  count(distinct sk_id_bureau) as loan_count\n",
    "from\n",
    "  bu_main_with_raw_dpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "920c7bd0-5909-4d90-8882-34c13c3578df",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "7. Creating cash_rev_flag"
    }
   },
   "outputs": [],
   "source": [
    "# # Define loan categories in lowercase\n",
    "# cash_loans = {\n",
    "#     'consumer credit', 'mortgage', 'car loan', 'microloan',\n",
    "#     'loan for working capital replenishment', 'loan for business development',\n",
    "#     'real estate loan', 'cash loan (non-earmarked)',\n",
    "#     'loan for the purchase of equipment', 'loan for purchase of shares (margin lending)'\n",
    "# }\n",
    "\n",
    "# revolving_loans = {\n",
    "#     'credit card', 'mobile operator loan', 'interbank credit'\n",
    "# }\n",
    "\n",
    "# # Convert 'CREDIT_TYPE' to lowercase and classify using when conditions\n",
    "# bu_main_with_raw_dpd = bu_main_with_raw_dpd.withColumn('CASH_REV_FLAG',\n",
    "#     F.when(F.lower(F.col('CREDIT_TYPE')).isin(*cash_loans), 'CASH')\n",
    "#     .when(F.lower(F.col('CREDIT_TYPE')).isin(*revolving_loans), 'REV')\n",
    "#     .otherwise('OTHER')\n",
    "# )\n",
    "\n",
    "# # Show the result\n",
    "# bu_main_with_raw_dpd.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c424e9bb-1d51-4f55-83a4-808141b9374a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bu_main_with_raw_dpd.createOrReplaceTempView('bu_main_with_raw_dpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ec1d10-8ff1-4b0d-8203-366ac385479a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "8. store the final base table in dbfs"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table if exists default.bureau_base;\n",
    "create table default.bureau_base as\n",
    "select\n",
    "  *\n",
    "from\n",
    "  bu_main_with_raw_dpd;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d792954-d27c-42b6-969d-52dae3ed0d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Now that Our Data is ready. We can start creating Dqliquency Features. I have divided features based on Level 1 and Level 2 (based on complexity of aggregations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3a0189-918e-4e51-bfc3-e8b398b28b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deliquency LEVEL 2 Variables Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d69bbb-1d35-42d6-9b35-d0e31782364c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "1. Loading the base table"
    }
   },
   "outputs": [],
   "source": [
    "# load the base data \n",
    "bu_base_1 = spark.sql(\"select * from default.bureau_base\")\n",
    "bu_base_1.createOrReplaceTempView(\"bu_base_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c39db6-1b1a-4dcd-b359-f44a8b30418e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "2. COUNT_DPD0P_XMOB"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bu_base_2 = bu_base_1\n",
    "\n",
    "\n",
    "mob_values = [3, 6, 9, 12, 15, 18, 24, 36]\n",
    "\n",
    "# For each MOB value, create a column that counts DPDs greater than 0 for each loan (SK_ID_BUREAU)\n",
    "for mob in mob_values:\n",
    "    # Select the dpd columns for the current MOB value (e.g., `dpd_1` to `dpd_36`)\n",
    "    dpd_cols = [f\"dpd_{i}\" for i in range(1, mob + 1)]\n",
    "    \n",
    "    # Create a new column for each MOB that counts the number of dpd values > 0 for each loan\n",
    "    bu_base_2 = bu_base_2.withColumn(\n",
    "        f\"COUNT_0P_{mob}MOB\",\n",
    "        sum(F.when(F.col(dpd) > 0, 1).otherwise(0) for dpd in dpd_cols)\n",
    "    )\n",
    "\n",
    "# Display or use df2 with the new COUNT_0P_<mob>MOB columns for each loan (SK_ID_BUREAU)\n",
    "bu_base_2.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7d89ec6-af87-4d11-ba3c-18fda43df4b1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "3. DEQ_MAX_COUNT_DPD0P_XMOB_{CASH/REV/ALL}"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mob_values = [3, 6, 9, 12, 15, 18, 24, 36]\n",
    "\n",
    "# # Filter the DataFrame to create separate DataFrames for CASH, REV, and ALL\n",
    "# df_cash = bu_base_2.filter(F.col(\"CASH_REV_FLAG\") == \"CASH\")\n",
    "# df_rev = bu_base_2.filter(F.col(\"CASH_REV_FLAG\") == \"REV\")\n",
    "df_all = bu_base_2\n",
    "\n",
    "# # Define aggregations for each variation of DEQ_MAX_COUNT_DPD0P_{X}MOB\n",
    "# aggregations_cash = {}\n",
    "# aggregations_rev = {}\n",
    "aggregations_all = {}\n",
    "\n",
    "for mob in mob_values:\n",
    "    # Define the aggregation for each MOB, calculating the max of COUNT_0P_{mob}MOB\n",
    "    # aggregations_cash[f\"DEQ_MAX_COUNT_DPD0P_{mob}MOB_CASH\"] = F.max(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    # aggregations_rev[f\"DEQ_MAX_COUNT_DPD0P_{mob}MOB_REV\"] = F.max(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    aggregations_all[f\"DEQ_MAX_COUNT_DPD0P_{mob}MOB_ALL\"] = F.max(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "\n",
    "# Apply the aggregations to each filtered DataFrame\n",
    "\n",
    "# df_aggregated_cash = df_cash.groupBy(\"SK_ID_CURR\").agg(\n",
    "#     *[aggregation.alias(name) for name, aggregation in aggregations_cash.items()]\n",
    "# )\n",
    "\n",
    "# df_aggregated_rev = df_rev.groupBy(\"SK_ID_CURR\").agg(\n",
    "#     *[aggregation.alias(name) for name, aggregation in aggregations_rev.items()]\n",
    "# )\n",
    "\n",
    "df_aggregated_all = df_all.groupBy(\"SK_ID_CURR\").agg(\n",
    "    *[aggregation.alias(name) for name, aggregation in aggregations_all.items()]\n",
    ")\n",
    "\n",
    "#Join all three aggregated DataFrames on SK_ID_CURR to get the final combined result\n",
    "# bu_features_1 = df_aggregated_cash.join(df_aggregated_rev, on=\"SK_ID_CURR\", how=\"outer\") \\\n",
    "#                              .join(df_aggregated_all, on=\"SK_ID_CURR\", how=\"outer\")\n",
    "\n",
    "bu_features_1 = df_aggregated_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0f3fcd-98dd-49fe-9f5a-df5f29ff3287",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "4. DEQ_SUM_COUNT_DPDP0P_XMOB_{CASH/REV/ALL}"
    }
   },
   "outputs": [],
   "source": [
    "mob_values = [3, 6, 9, 12, 15, 18, 24, 36]\n",
    "\n",
    "# Filter the DataFrame to create separate DataFrames for CASH, REV, and ALL\n",
    "# df_cash = bu_base_2.filter(F.col(\"CASH_REV_FLAG\") == \"CASH\")\n",
    "# df_rev = bu_base_2.filter(F.col(\"CASH_REV_FLAG\") == \"REV\")\n",
    "df_all = bu_base_2\n",
    "\n",
    "# Define aggregations for each variation of DEQ_SUM_COUNT_DPD0P_{X}MOB\n",
    "# aggregations_cash = {}\n",
    "# aggregations_rev = {}\n",
    "aggregations_all = {}\n",
    "\n",
    "for mob in mob_values:\n",
    "    # Define the aggregation for each MOB, calculating the sum of COUNT_0P_{mob}MOB\n",
    "    # aggregations_cash[f\"DEQ_SUM_COUNT_DPD0P_{mob}MOB_CASH\"] = F.sum(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    # aggregations_rev[f\"DEQ_SUM_COUNT_DPD0P_{mob}MOB_REV\"] = F.sum(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    aggregations_all[f\"DEQ_SUM_COUNT_DPD0P_{mob}MOB_ALL\"] = F.sum(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "\n",
    "# Apply the aggregations to each filtered DataFrame\n",
    "\n",
    "# df_aggregated_cash = df_cash.groupBy(\"SK_ID_CURR\").agg(\n",
    "#     *[aggregation.alias(name) for name, aggregation in aggregations_cash.items()]\n",
    "# )\n",
    "\n",
    "# df_aggregated_rev = df_rev.groupBy(\"SK_ID_CURR\").agg(\n",
    "#     *[aggregation.alias(name) for name, aggregation in aggregations_rev.items()]\n",
    "# )\n",
    "\n",
    "df_aggregated_all = df_all.groupBy(\"SK_ID_CURR\").agg(\n",
    "    *[aggregation.alias(name) for name, aggregation in aggregations_all.items()]\n",
    ")\n",
    "\n",
    "#Join all three aggregated DataFrames on SK_ID_CURR to get the final combined result\n",
    "# bu_features_2 = df_aggregated_cash.join(df_aggregated_rev, on=\"SK_ID_CURR\", how=\"outer\") \\\n",
    "#                              .join(df_aggregated_all, on=\"SK_ID_CURR\", how=\"outer\")\n",
    "\n",
    "bu_features_2 = df_aggregated_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e24ebce-d2f6-4a6d-ba1b-4ab1891c8e37",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "5. DEQ_AVG_COUNT_DPD0P_XMOB_{CASH/REV/ALL}"
    }
   },
   "outputs": [],
   "source": [
    "mob_values = [3, 6, 9, 12, 15, 18, 24, 36]\n",
    "\n",
    "# Filter the DataFrame to create separate DataFrames for CASH, REV, and ALL\n",
    "# df_cash = bu_base_2.filter(F.col(\"CASH_REV_FLAG\") == \"CASH\")\n",
    "# df_rev = bu_base_2.filter(F.col(\"CASH_REV_FLAG\") == \"REV\")\n",
    "df_all = bu_base_2\n",
    "\n",
    "# Define aggregations for each variation of DEQ_AVG_COUNT_DPD0P_{X}MOB\n",
    "# aggregations_cash = {}\n",
    "# aggregations_rev = {}\n",
    "aggregations_all = {}\n",
    "\n",
    "for mob in mob_values:\n",
    "    # Define the aggregation for each MOB, calculating the sum of COUNT_0P_{mob}MOB\n",
    "    # aggregations_cash[f\"DEQ_AVG_COUNT_DPD0P_{mob}MOB_CASH\"] = F.avg(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    # aggregations_rev[f\"DEQ_AVG_COUNT_DPD0P_{mob}MOB_REV\"] = F.avg(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    aggregations_all[f\"DEQ_AVG_COUNT_DPD0P_{mob}MOB_ALL\"] = F.avg(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "\n",
    "# Apply the aggregations to each filtered DataFrame\n",
    "\n",
    "# df_aggregated_cash = df_cash.groupBy(\"SK_ID_CURR\").agg(\n",
    "#     *[aggregation.alias(name) for name, aggregation in aggregations_cash.items()]\n",
    "# )\n",
    "\n",
    "# df_aggregated_rev = df_rev.groupBy(\"SK_ID_CURR\").agg(\n",
    "#     *[aggregation.alias(name) for name, aggregation in aggregations_rev.items()]\n",
    "# )\n",
    "\n",
    "df_aggregated_all = df_all.groupBy(\"SK_ID_CURR\").agg(\n",
    "    *[aggregation.alias(name) for name, aggregation in aggregations_all.items()]\n",
    ")\n",
    "\n",
    "#Join all three aggregated DataFrames on SK_ID_CURR to get the final combined result\n",
    "# bu_features_3 = df_aggregated_cash.join(df_aggregated_rev, on=\"SK_ID_CURR\", how=\"outer\") \\\n",
    "#                              .join(df_aggregated_all, on=\"SK_ID_CURR\", how=\"outer\")\n",
    "\n",
    "bu_features_3 = df_aggregated_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce55f17-24b7-47e0-b5af-ef19520c8454",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "6. DEQ_MAX_COUNT_DPD0P_XMOB_ACTIVE_LOANS"
    }
   },
   "outputs": [],
   "source": [
    "mob_values = [3, 6, 9, 12, 15, 18, 24, 36]\n",
    "\n",
    "# Filter the DataFrame to create separate DataFrames for Active Loans\n",
    "df_active = bu_base_2.filter(F.col(\"CREDIT_ACTIVE\") == \"Active\")\n",
    "df_closed = bu_base_2.filter(F.col(\"CREDIT_ACTIVE\") == \"Closed\")\n",
    "\n",
    "# Define aggregations for each variation of DEQ_MAX_COUNT_DPD0P_{X}MOB\n",
    "aggregations_active = {}\n",
    "aggregations_closed = {}\n",
    "\n",
    "\n",
    "for mob in mob_values:\n",
    "    # Define the aggregation for each MOB, calculating the max of COUNT_0P_{mob}MOB\n",
    "    aggregations_active[f\"DEQ_MAX_COUNT_DPD0P_{mob}MOB_ACTIVE_LOANS\"] = F.max(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    aggregations_closed[f\"DEQ_MAX_COUNT_DPD0P_{mob}MOB_CLOSED_LOANS\"] = F.max(F.col(f\"COUNT_0P_{mob}MOB\"))\n",
    "    \n",
    "\n",
    "# Apply the aggregations to each filtered DataFrame\n",
    "\n",
    "df_aggregated_active = df_active.groupBy(\"SK_ID_CURR\").agg(\n",
    "    *[aggregation.alias(name) for name, aggregation in aggregations_active.items()]\n",
    ")\n",
    "\n",
    "df_aggregated_closed = df_closed.groupBy(\"SK_ID_CURR\").agg(\n",
    "    *[aggregation.alias(name) for name, aggregation in aggregations_closed.items()]\n",
    ")\n",
    "\n",
    "#Join all 2 aggregated DataFrames on SK_ID_CURR to get the final combined result\n",
    "bu_features_4 = df_aggregated_active\n",
    "bu_features_5 = df_aggregated_closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8b44e5f-a888-4e58-8a98-28a1a727227e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "6. Joining all the 5 category of variables in one df"
    }
   },
   "outputs": [],
   "source": [
    "bu_features_level2 = bu_features_1.join(bu_features_2, on=\"SK_ID_CURR\", how = \"outer\").join(bu_features_3,on=\"SK_ID_CURR\", how = \"outer\").join(bu_features_4,on=\"SK_ID_CURR\", how = \"outer\").join(bu_features_5,on=\"SK_ID_CURR\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39289ae8-09b0-40a9-bab4-21dc554bd39d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bu_features_level2.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18618f50-daa1-48ed-bd53-467286d5269d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bu_features_level2.createOrReplaceTempView(\"bu_features_level2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5736c5f1-213f-468a-abf1-1419502c97ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table if exists default.bu_features_level2;\n",
    "create table default.bu_features_level2 as\n",
    "select\n",
    "  *\n",
    "from\n",
    "  bu_features_level2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b68ed358-9924-4b2d-98e4-0094ab8e5548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Done with Creating Deliquency Based features on OFF US Data"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2501060672919903,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SM_DEQ_Feature_Creation_Level2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
